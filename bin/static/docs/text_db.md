

[ËøîÂõû](/mag/doc_detail/main)

---

# üìö ÊñáÊú¨ÂêëÈáèÂ∫ìÂèäÂÖ≥ÈîÆÈÖçÁΩÆËØ¥Êòé

> **ÊñáÊú¨ÂêëÈáèÂ∫ì** ÊòØ‰∏ÄÁßçÊô∫ËÉΩÂåñÁöÑÊñáÊú¨Â§ÑÁêÜÁ≥ªÁªüÔºåËÉΩÂ§üËá™Âä®Êâ´ÊèèÊåáÂÆöÁõÆÂΩï‰∏≠ÁöÑÊñáÊú¨Êñá‰ª∂„ÄÅÂØπÊñáÊú¨ËøõË°åÊô∫ËÉΩÂàÜÂùóÔºåÂπ∂Â∞Ü"ÊñáÊú¨Âùó"ËΩ¨Êç¢‰∏∫Âõ∫ÂÆöÈïøÂ∫¶ÁöÑÊï∞ÂÄºÂêëÈáè„ÄÇÁ≥ªÁªüÈááÁî®Â§öÁßçÂÖàËøõÊñπÊ≥ïÂØπ"ÊñáÊú¨Âùó"ËøõË°åÊ£ÄÁ¥¢Âè¨ÂõûÔºåÂπ∂‰ΩøÁî®È´òÁ≤æÂ∫¶ÁöÑÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÂØπÂè¨ÂõûÁªìÊûúËøõË°åÁ≤æÊéíÂ∫è„ÄÇ‰∏ªË¶ÅÂ∫îÁî®Âú∫ÊôØÂåÖÊã¨Êµ∑ÈáèÊñáÊú¨Êñá‰ª∂ÁöÑÂÜÖÂÆπÊ®°Á≥äÊ£ÄÁ¥¢„ÄÅÈù¢ÂêëÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÁ≠â„ÄÇ

---

## üìÅ ÊîØÊåÅÁöÑÊñá‰ª∂Á±ªÂûã

Á≥ªÁªüÂΩìÂâçÊîØÊåÅÂ∏ÇÈù¢‰∏äÁªùÂ§ßÂ§öÊï∞Â∏∏ËßÅÁöÑÊñáÊú¨Êñá‰ª∂Á±ªÂûãÔºåÂåÖÊã¨ PDF„ÄÅWord„ÄÅExcel„ÄÅPPT„ÄÅTXT„ÄÅMarkdown Á≠â„ÄÇÈíàÂØπ‰∏çÂêåÊñá‰ª∂ÁâπÁÇπÔºåÁ≥ªÁªü‰ºöËøõË°åÈíàÂØπÊÄßÁöÑÁâπÊÆäÂ§ÑÁêÜÔºö

| Êñá‰ª∂Á±ªÂûã | Êâ©Â±ïÂêç | Â§ÑÁêÜÊñπÊ≥ïËØ¥Êòé |
|:---------:|:-------:|:-------------|
| **TXT** | `.txt` | Â¶ÇÊûúÊÆµËêΩÈó¥Êúâ‰∏Ä‰∏™Á©∫Ë°åÔºàÂç≥‰∏§‰∏™`\n\n`ÔºâÔºåÁ≥ªÁªüÂ∞ÜÈªòËÆ§ËØ•Ê†ºÂºè‰∏∫Áî®Êà∑ÊåáÂÆöÁöÑÊñáÊú¨ÂùóÂàáÂâ≤ÊñπÊ≥ïÔºåÂπ∂Â∞ΩÈáèÈÅøÂÖçÂØπÂ§ßÊÆµËêΩËøõË°åÂàáÂâ≤ÔºåÂ∞èÊÆµËêΩÂêëÂêéÂêàÂπ∂„ÄÇ |
| **PDF** | `.pdf` | Á≥ªÁªü‰ºöÂ∞ùËØïÂØπPDF‰∏≠ËØªÂá∫ÁöÑÊú™Ê≠£Á°ÆÂàÜÊÆµÁöÑÊñáÊú¨ËøõË°åÊÆµËêΩ‰øÆÂ§ç„ÄÇÂ¶ÇÊûúÊñáÊ°£‰∏≠Â≠òÂú®Ë°®Ê†ºÔºåÂè™ÊúâÂÖ∑ÊúâÂÆåÊï¥ËæπÊ°ÜÁöÑË°®Ê†ºËÉΩË¢´ËØÜÂà´ÔºåÊï¥‰∏™Ë°®Ê†ºÂ∞ÜË¢´ËΩ¨Êç¢‰∏∫MarkdownÊ†ºÂºèÂπ∂ËßÜ‰∏∫‰∏Ä‰∏™ÂÆåÊï¥ÁöÑÊñáÊú¨ÂùóÔºå‰∏çËøõË°åÂàáÂâ≤„ÄÇ |
| **MS Word** | `.doc/.docx` | ÊñáÊú¨ÂùóÂàáÂâ≤ÊñπÊ≥ïÂêåTXT„ÄÇÂ¶ÇÊûúÊñáÊ°£‰∏≠Â≠òÂú®Ë°®Ê†ºÔºåÊï¥‰∏™Ë°®Ê†ºÂ∞ÜË¢´ËΩ¨Êç¢‰∏∫MarkdownÊ†ºÂºèÂπ∂ËßÜ‰∏∫‰∏Ä‰∏™ÂÆåÊï¥ÁöÑÊñáÊú¨ÂùóÔºå‰∏çËøõË°åÂàáÂâ≤„ÄÇ |
| **MS Excel** | `.xls/.xlsx` | Êï¥‰∏™Ê†áÁ≠æÈ°µ‰∏≠ÁöÑË°®Ê†ºÂ∞ÜË¢´ËΩ¨Êç¢‰∏∫MarkdownÊ†ºÂºèÂπ∂ËßÜ‰∏∫‰∏Ä‰∏™ÂÆåÊï¥ÁöÑÊñáÊú¨ÂùóÔºå‰∏çËøõË°åÂàáÂâ≤„ÄÇÂ¶ÇÊûúË°®Ê†ºÂæàÂ§ßÔºåÂª∫ËÆÆÂÖàËΩ¨‰∏∫CSVÊ†ºÂºèÔºåÁ≥ªÁªüÂ∞ÜËøõË°åÁâπÊÆäÂ§ÑÁêÜ„ÄÇ |
| **CSV** | `.csv` | ÈªòËÆ§ÂøÖÈ°ªÊúâË°®Â§¥Â≠òÂú®ÔºåÊï∞ÊçÆÁöÑÊØè‰∏ÄË°åÈÉΩÂ∞ÜË¢´Â§ÑÁêÜ‰∏∫Â§ö‰∏™ÈîÆÂÄºÂØπÂ∫îÁöÑJSONÊï∞ÊçÆÔºåÂÖ∂‰∏≠Ë°®Â§¥‰∏≠ÁöÑÂ≠óÊÆµÂêç‰∏∫ÈîÆ„ÄÅË°å‰∏≠ÁöÑÊï∞ÊçÆÂçïÂÖÉ‰∏∫ÂÄºÔºåÊØèË°å‰∏∫‰∏Ä‰∏™ÊñáÊú¨ÂùóÔºå‰∏çËøõË°åÂàáÂâ≤„ÄÇ |
| **Markdown** | `.md` | Â§ßÊ®°ÂûãÈ¶ñÈÄâÊ†ºÂºè„ÄÇÈíàÂØπÊ†áÈ¢òÂèäÂºïÈ¢ÜÁöÑÊÆµËêΩÂÅö‰∫ÜÁâπÂà´Â§ÑÁêÜÔºåÊ†áÈ¢ò+ÊÆµËêΩÂΩ¢ÊàêÁöÑÊñáÊú¨Âùó‰∏çÂÅöËøõ‰∏ÄÊ≠•ÂàáÂâ≤‰∏éÂêàÂπ∂„ÄÇÈíàÂØπË°®Ê†º„ÄÅÂºïÁî®„ÄÅÂàóË°®„ÄÅ‰ª£Á†ÅÂùóÁ≠âÂÜÖÂÆπÂÅö‰∫ÜÁâπÂà´Ê†áÊ≥®„ÄÇ |
| **HTML** | `.html/.htm` | Â∞ÜHTMLËΩ¨Êç¢‰∏∫MarkdownÊ†ºÂºèÔºåÁÑ∂ÂêéËøõË°åÂ§ÑÁêÜÔºåÂ§ÑÁêÜÊñπÂºèÂêåMarkdown„ÄÇ |
| **MS PPT** | `.ppt/.pptx` | ÊñáÊú¨ÂùóÂàáÂâ≤ÊñπÊ≥ïÂêåTXT„ÄÇÂ¶ÇÊûúPPT‰∏≠Â≠òÂú®Ë°®Ê†ºÔºåÊï¥‰∏™Ë°®Ê†ºÂ∞ÜË¢´ËΩ¨Êç¢‰∏∫MarkdownÊ†ºÂºèÂπ∂ËßÜ‰∏∫‰∏Ä‰∏™ÂÆåÊï¥ÁöÑÊñáÊú¨ÂùóÔºå‰∏çËøõË°åÂàáÂâ≤„ÄÇ |

---

## üî™ ÊñáÊú¨ÂùóÂ§ÑÁêÜÊú∫Âà∂

ÊñáÊú¨Â∫ì‰ºöÂ∞ÜËæÉÈïøÁöÑÊñáÊú¨ÂÜÖÂÆπÊô∫ËÉΩÂàáÂâ≤‰∏∫Â§ö‰∏™Â∞èÊÆµÊñáÊú¨ÔºåËøôÂú®ÂΩìÂâçÊäÄÊúØÊù°‰ª∂‰∏ãÊòØÂøÖË¶ÅÁöÑÔºö

### ‰∏∫‰ªÄ‰πàÈúÄË¶ÅÊñáÊú¨ÂàÜÂùóÔºü

- **üîç ËØ≠‰πâ‰ø°ÊÅØ‰øùÊåÅ**ÔºöÂ∞ÜÊñáÊú¨ÂêëÈáèÂåñÊó∂ÔºåËøáÈïøÁöÑÊñáÊú¨ÂÆπÊòìÊ®°Á≥äËØ≠‰πâ‰ø°ÊÅØ„ÄÇÂú®‰ΩøÁî®Áî®Êà∑ËæìÂÖ•ÁöÑÈóÆÈ¢òÊêúÁ¥¢ÊñáÊú¨ÂùóÊó∂ÔºåÂü∫‰∫éÂêëÈáèÁõ∏‰ººÊÄßÊØîÂØπÁöÑÈïøÊñáÊú¨‰∏éÁî®Êà∑ÈóÆÈ¢òÁõ∏ÂÖ≥ÊÄßËÆ°ÁÆóÊïàÊûúÂ∞ÜÂ§ßÊâìÊäòÊâ£„ÄÇ

- **üìè Ê®°ÂûãËæìÂÖ•ÈôêÂà∂**ÔºöÊñáÊú¨ÂêëÈáèÂåñÊ®°ÂûãÈÄöÂ∏∏ÊúâËæìÂÖ•ÈïøÂ∫¶ÈôêÂà∂„ÄÇÂ¶ÇBERT„ÄÅBGEÁ≠âÊ®°ÂûãÁöÑËæìÂÖ•TokenÊï∞ÈÄöÂ∏∏ÈôêÂà∂‰∏∫512ÔºåËøáÈïøÁöÑÊñáÊú¨ÂæÄÂæÄ‰ºöË¢´Áõ¥Êé•Êà™Êñ≠‰∏¢ÂºÉ„ÄÇ

- **ü§ñ Â§ßÊ®°ÂûãÂÖºÂÆπÊÄß**ÔºöÂ§ßËØ≠Ë®ÄÊ®°ÂûãÈÄöÂ∏∏ÊúâËæìÂÖ•ÈïøÂ∫¶ÈôêÂà∂„ÄÇÂú®Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÁ≠âÂ∫îÁî®‰∏≠ÔºåÂ¶ÇÊûúÊ£ÄÁ¥¢Âá∫ÁöÑÊñáÊú¨ÈïøÂ∫¶Ë∂ÖÂá∫Â§ßÊ®°ÂûãÁöÑËæìÂÖ•ÈïøÂ∫¶ÈôêÂà∂ÔºåÂ∞ÜË¢´Áõ¥Êé•Êà™Êñ≠‰∏¢ÂºÉ„ÄÇ

### ÊñáÊú¨ÂùóÈïøÂ∫¶ÈÖçÁΩÆÂª∫ËÆÆ

Èâ¥‰∫éÂ§ßÂ§öÊï∞ÊñáÊú¨ÂêëÈáèÂåñÊ®°ÂûãÁöÑËæìÂÖ•ÈïøÂ∫¶ÈôêÂà∂‰∏∫512 TokenÔºåÂú®ÊñáÊú¨Â∫ìËÆæÁΩÆÊó∂ÊñáÊú¨ÂùóÁöÑÊúÄÂ§ßÈïøÂ∫¶ÈôêÂà∂Â∫îËÄÉËôëËØ•Âõ†Á¥†Ôºö

| ËØ≠Ë®Ä | ÊúÄÂ§ßÊñáÊú¨ÂùóÈïøÂ∫¶ËÆæÁΩÆ | ËØ¥Êòé |
|:-----:|:-----------------:|:-----|
| **‰∏≠Êñá** | 512 Token ÂØπÂ∫î 512 ‰∏™‰∏≠ÊñáËØçÁªÑ | ‰øùÈô©Ëµ∑ËßÅÂ≠óÁ¨¶ÈïøÂ∫¶ËÆæÁΩÆ‰∏çË∂ÖËøá **1000**ÔºåÈªòËÆ§ÂÄº‰∏∫ **800** |
| **Ëã±Êñá** | 512 Token ÂØπÂ∫î 512 ‰∏™ÂçïËØç | ‰øùÈô©Ëµ∑ËßÅÂ≠óÁ¨¶ÈïøÂ∫¶ËÆæÁΩÆ‰∏çË∂ÖËøá **2000**ÔºåÈªòËÆ§ÂÄº‰∏∫ **800** |

Ëá≥‰∫é**ÊúÄÂ∞èÊñáÊú¨ÂùóÈïøÂ∫¶**ÈôêÂà∂ÔºåÂèØÊ†πÊçÆÂÖ∑‰ΩìÂú∫ÊôØËÆæÁΩÆÔºåÈªòËÆ§ÂÄº **500**„ÄÇÂΩìÁ≥ªÁªüËØÜÂà´Âá∫ÁöÑÊÆµËêΩÂ∞è‰∫éÊúÄÂ∞èÊñáÊú¨ÂùóÈïøÂ∫¶Êó∂ÔºåÈªòËÆ§‰ºöÂêëÂêéÂêàÂπ∂ÊÆµËêΩÔºåÁõ¥Ëá≥ÈïøÂ∫¶Á¨¶ÂêàÊúÄÂ∞èÈïøÂ∫¶Ë¶ÅÊ±Ç„ÄÇ

---

## üß† ÊñáÊú¨ÂêëÈáèÂåñÊñπÊ≥ï

Êú¨Á≥ªÁªüÊîØÊåÅÂ§öÁßçÂÖàËøõÁöÑÊñáÊú¨ÂêëÈáèÂåñÊäÄÊúØÔºö

### **GloVe** - ÊµÖÂ±ÇËØ≠‰πâÂêëÈáèÂåñ
- **ÁâπÁÇπ**ÔºöGloVeÁ•ûÁªèÁΩëÁªúÊ®°ÂûãÈÄöÂ∏∏ËæÉÂ∞èÔºåËæìÂÖ•ÁöÑËØçÂ∫èÂàóÈó¥ÁöÑÂÖ≥ËÅîÁ™óÂè£ÈïøÂ∫¶ÈÄöÂ∏∏‰∏∫5
- **‰ºòÂäø**ÔºöËÆ≠ÁªÉÈÄüÂ∫¶Âø´ÔºåËµÑÊ∫êÂç†Áî®Â∞ë
- **Â±ÄÈôê**ÔºöÈöæ‰ª•ÊçïÊçâÊñáÊú¨ËØçÊ±áÈó¥ÈïøË∑ùÁ¶ªÁöÑÂÖ≥ËÅîÂÖ≥Á≥ªÔºåËØ≠‰πâÁõ∏ÂÖ≥ÊÄß‰∏∫"ÊµÖÂ±ÇËØ≠‰πâ"
- **Â∫îÁî®**ÔºöÁ≥ªÁªüÂÜÖÁΩÆ‰∫ÜÂú®"‰∫∫Ê∞ëÊó•Êä•"Á≠âÂ§ßÂûãÊñáÊú¨ÊùêÊñô‰∏äÈ¢ÑËÆ≠ÁªÉÁöÑGloVeÊ®°Âûã
- **Êâ©Â±ï**ÔºöÊèê‰æõGloVeÊ®°ÂûãÁöÑËá™ËÆ≠ÁªÉÂäüËÉΩÔºåÂèØÂú®ËøõË°å"È¢ÜÂüüËØçÊ±áËØÜÂà´"ÂêéÔºåËÆ≠ÁªÉËÉΩÈ´òÂ∫¶‰ΩìÁé∞Áî®Êà∑È¢ÜÂüüÊï∞ÊçÆÁâπÁÇπÁöÑËá™ÂÆö‰πâÊ®°Âûã

### **DistillBERT** - Ê∑±Â±ÇËØ≠‰πâÂêëÈáèÂåñ
- **ÁâπÁÇπ**ÔºöBERTÊ®°ÂûãÁöÑËí∏È¶èÈ¢ÑËÆ≠ÁªÉÁâàÊú¨ÔºåÁî®‰∫éÊñáÊú¨Êï∞ÊçÆÂêëÈáèÂåñ
- **‰ºòÂäø**ÔºöÊ≥®ÊÑèÂäõÊú∫Âà∂ÂñÑ‰∫éÊçïÊçâËØçÊ±áÈó¥ÁöÑÈïøË∑ùÁ¶ª‰æùËµñÂÖ≥Á≥ªÔºåËØ≠‰πâÁõ∏ÂÖ≥ÊÄß‰∏∫"Ê∑±Â±ÇËØ≠‰πâ"
- **ÊäÄÊúØ**ÔºöÊú¨Ë∫´‰∏∫Â∫èÂàóÂåñÊ®°ÂûãÔºåËØçÂ∫èÂàóÂèØ‰ª•Áõ¥Êé•ÁîüÊàêÂè•ÂêëÈáèÔºå‰∏çÊ∂âÂèäÁ±ª‰ººGloVeÁöÑËØçÂêëÈáè-Âè•ÂêëÈáèÁöÑÂä†ÊùÉÂπ≥ÂùáËΩ¨Êç¢
- **ÊïàÁéá**Ôºö‰∏éBERTÊÄßËÉΩÊó†ÂºÇÔºå‰ΩÜ‰ΩìÈáèÂ∞è70%Ôºà250MÔºâÔºåÈÄÇÂêàÊúçÂä°Á´ØÈÉ®ÁΩ≤

### ÊÄßËÉΩÊéíÂ∫è
Ê†πÊçÆÁ≥ªÁªüÂÆûÊìçÁªèÈ™åÔºåÂêÑÁßçÂêëÈáèÂåñÊñπÊ≥ïÁöÑÊ£ÄÁ¥¢ÊïàÊûúÊéíÂ∫è‰∏∫Ôºö
**Ëá™ËÆ≠ÁªÉGloVe > DistillBERT > È¢ÑËÆ≠ÁªÉGloVe**

---

## üîç ÂêëÈáèÁ¥¢ÂºïÊñπÊ≥ï

Êú¨Á≥ªÁªü‰∏ªË¶ÅÊîØÊåÅ‰∏âÂ§ßÂêëÈáèÁ¥¢ÂºïÊäÄÊúØ‰ΩìÁ≥ªÔºö

| Á¥¢ÂºïÊñπÊ≥ïÂêçÁß∞ | Á¥¢ÂºïÁ±ªÂûã | ‰ºòÁÇπ | Áº∫ÁÇπ | ÈÄÇÁî®Âú∫ÊôØ |
|:------------:|:--------:|:-----|:-----|:---------|
| **HNSW** | ÁΩëÁªúÂõæ | Ê£ÄÁ¥¢ÈÄüÂ∫¶ÊûÅÂø´ | ÊûÑÂª∫Á¥¢ÂºïÈÄüÂ∫¶ÊûÅÊÖ¢ | ‰∫∫ËÑ∏ËØÜÂà´Á≠âÂõæÂÉèÊûÅÈÄüÊ£ÄÁ¥¢ |
| **E2LSH** | ÂìàÂ∏åÁÆóÊ≥ï | Ê£ÄÁ¥¢ÈÄüÂ∫¶‰∏éÁ¥¢ÂºïÊûÑÂª∫ÈÄüÂ∫¶ÂùáÂ∞öÂèØ | Âè¨ÂõûÁ≤æÂ∫¶‰∏ÄËà¨ | ‰∏≠Á≠âËßÑÊ®°Êï∞ÊçÆÊ£ÄÁ¥¢ |
| **ÊâÅÂπ≥Á¥¢Âºï** | Âπ∂Ë°åÁ∫øÊÄßÊêúÁ¥¢ | Âè¨ÂõûÁ≤æÂ∫¶100% | Ê£ÄÁ¥¢ÈÄüÂ∫¶‰∏ÄËà¨ | Â∞èËßÑÊ®°ÊñáÊú¨Â∫ìÂú∫ÊôØ |

Âú®ÂÆûË∑µ‰∏≠ÔºåÈúÄÊ†πÊçÆÂú∫ÊôØÈúÄÊ±ÇÁ°ÆÂÆöÁ¥¢ÂºïÊñπÊ≥ï„ÄÇÂ¶ÇÂú®Â∞èËßÑÊ®°ÊñáÊú¨Â∫ìÂú∫ÊôØ‰∏≠Ôºå‰ΩøÁî®ÊâÅÂπ≥Á¥¢ÂºïÂç≥ÂèØÔºõËÄåÂú®ÈúÄË¶ÅÊûÅÈÄüÊ£ÄÁ¥¢ÁöÑÂú∫ÊôØ‰∏≠Ôºå‰ΩøÁî®HNSWËæÉÂ•Ω„ÄÇ

---

## üîé Ê£ÄÁ¥¢ÊñπÊ≥ï

Êú¨Á≥ªÁªüÊîØÊåÅÂ§öÁßçÊ£ÄÁ¥¢Á≠ñÁï•ÔºåÊó¢ÂåÖÊã¨‰º†ÁªüÁöÑÂü∫‰∫éÂÖ≥ÈîÆËØçÂåπÈÖçÁöÑBM25Ê£ÄÁ¥¢ÊñπÊ≥ïÔºå‰πüÂåÖÊã¨‰∫∫Â∑•Êô∫ËÉΩÊó∂‰ª£ÊâÄÈááÁî®ÁöÑÂü∫‰∫éÂêëÈáèÁõ∏‰ººÂ∫¶ÁöÑËØ≠‰πâÁõ∏ÂÖ≥ÊÄßÊ£ÄÁ¥¢ÊñπÊ≥ïÔºåÂπ∂‰∏îÂèØ‰ª•Â∞Ü‰∏§ÁßçÊñπÊ≥ïÁöÑÊ£ÄÁ¥¢ÁªìÊûúËøõË°åÂ§öË∑ØÂè¨ÂõûÁªºÂêàÊéíÂ∫èÔºö

| Ê£ÄÁ¥¢ÊñπÊ≥ïÂêçÁß∞ | ËØ¥Êòé | ‰ºòÁÇπ | Áº∫ÁÇπ | ÈÄÇÁî®Âú∫ÊôØ |
|:------------:|:-----|:-----|:-----|:---------|
| **BM25** | Âü∫‰∫éÂÖ≥ÈîÆËØçÂåπÈÖçÂíåÂÖ≥ÈîÆËØçÁöÑTF-IDFÁ≠âÂàÜÂÄºËÆ°ÁÆóÂæóÂàÜÂπ∂ÊéíÂ∫èÂè¨Âõû | ‰∏çÂèóÊñáÊú¨ÈïøÂ∫¶ÈôêÂà∂ÔºåÊ£ÄÁ¥¢ÈÄüÂ∫¶Âø´ | Êó†Ê≥ïËÆ°ÁÆóËØ≠‰πâÁõ∏‰ººÊÄßÔºåÂøÖÈ°ªÁ≤æÁ°ÆÂåπÈÖçËØç | Á≤æÁ°ÆÂÖ≥ÈîÆËØçÊêúÁ¥¢ |
| **ÂêëÈáèÁõ∏‰ººÊÄß** | Âü∫‰∫éÂêëÈáèÈó¥ÁöÑÊ¨ßÂºèË∑ùÁ¶ªËøõË°åÁõ∏‰ººÊÄßÊéíÂ∫èÂè¨Âõû | ËÉΩÂ§üËÆ°ÁÆóËØ≠‰πâÁõ∏‰ººÊÄßÔºåÈÄÇÂêàÊñáÊú¨Ê®°Á≥äÊêúÁ¥¢ | ÂèóÊñáÊú¨ÈïøÂ∫¶ÈôêÂà∂ÔºåÈïøÊñáÊú¨ÂêëÈáèÁöÑËØ≠‰πâ‰ø°ÊÅØÊ®°Á≥ä | ËØ≠‰πâÁõ∏‰ººÊÄßÊêúÁ¥¢ |
| **ÁªºÂêàÊ£ÄÁ¥¢** | ÁªºÂêàBM25ÂíåÂêëÈáèÁõ∏‰ººÊÄßÁöÑÊ£ÄÁ¥¢ÁªìÊûúËøõË°åÂ§öË∑ØÂè¨ÂõûÁªìÊûúÁªºÂêàÊéíÂ∫è | ÂêåÊó∂Âê∏Á∫≥‰∏§ÁßçÊ£ÄÁ¥¢ÊñπÊ≥ïÁöÑ‰ºòÁÇπÔºåÈÅøÂÖç‰∏§ÁßçÊñπÊ≥ïÁº∫ÁÇπ | ËÆ°ÁÆóÈáèÂ§ßÔºåÂú®Êµ∑ÈáèÊï∞ÊçÆ‰∏≠ÈÄüÂ∫¶ÊÖ¢ | È´òÁ≤æÂ∫¶ÁªºÂêàÊêúÁ¥¢ |

---

## üéØ Áî®Êà∑Ê£ÄÁ¥¢ÈóÆÈ¢òËß£ÊûêÊñπÊ≥ï

Âú®‰ø°ÊÅØÊ£ÄÁ¥¢‰∏≠ÔºåÁî±‰∫éÁî®Êà∑ÁöÑÂè£ËØ≠ÂåñË°®ËææÁ≠âÈóÆÈ¢òÔºåÁªèÂ∏∏Âá∫Áé∞"Áî®Êà∑ÊÑèÂõæÁêÜËß£Âõ∞Èöæ"ÈóÆÈ¢òÔºåÂç≥Á≥ªÁªü‰∏çËÉΩ‰ΩøÁî®ÊúÄ‰ºòÁöÑÊ£ÄÁ¥¢ËØ≠Âè•ÂéªÊü•ËØ¢Áî®Êà∑ÊÉ≥Ë¶ÅËé∑ÂæóÁöÑ‰ø°ÊÅØ„ÄÇÊú¨Á≥ªÁªü‰∏∫‰∫ÜËß£ÂÜ≥‰ª•‰∏äÈóÆÈ¢òÔºåÂä†ÂÖ•‰∫ÜÂ§ßÊ®°ÂûãËß£ÊûêÊ£ÄÁ¥¢ÈóÆÈ¢òÁöÑÂèØÈÄâÈÖçÁΩÆÔºö

| Ëß£ÊûêÊñπÊ≥ï | ËØ¥Êòé | ‰ºòÁÇπ | Áº∫ÁÇπ | ÈÄÇÁî®Âú∫ÊôØ |
|:--------:|:-----|:-----|:-----|:---------|
| **Áî®Êà∑ÂéüÂßãÈóÆÈ¢ò** | ‰ΩøÁî®Áî®Êà∑ËæìÂÖ•ÁöÑÈóÆÈ¢òÁõ¥Êé•Ê£ÄÁ¥¢ | ÁÆÄÂçï„ÄÅ‰∏çÊòìÂá∫Èîô„ÄÅÂìçÂ∫îÈÄüÂ∫¶Âø´ | Áî®Êà∑ÈóÆÈ¢òÈÄöÂ∏∏Âè£ËØ≠ÂåñÔºåÂú®ËøûÁª≠ÂØπËØù‰∏≠ËæìÂÖ•ÁöÑÈóÆÈ¢òÊó†‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºåÊó†Ê≥ïÊ£ÄÁ¥¢ | ÁÆÄÂçïÊü•ËØ¢Âú∫ÊôØ |
| **Â§ßÊ®°ÂûãËß£ÊûêÊ£ÄÁ¥¢ÈóÆÈ¢ò** | Ê†πÊçÆÁî®Êà∑ËæìÂÖ•ÁöÑÈóÆÈ¢òÁî±Â§ßÊ®°ÂûãÈáçÊñ∞ÁîüÊàêÂêàÈÄÇÁöÑÊ£ÄÁ¥¢ÈóÆÈ¢ò | ËÉΩÂ§üÁîüÊàêÊõ¥Âä†ÈÄÇÂêàÊ£ÄÁ¥¢ÁöÑÂÆåÊï¥ËØ≠Âè•ÔºåÂú®ËøûÁª≠ÂØπËØù‰∏≠‰ªçËÉΩÊ†πÊçÆ‰∏ä‰∏ãÊñáÁîüÊàêÂÆåÊï¥ÁöÑÊ£ÄÁ¥¢ÈóÆÈ¢ò | ‰æùËµñ‰∫éÂ§ßÊ®°ÂûãÁöÑÁî®Êà∑ÊÑèÂõæÁêÜËß£ÂíåÁîüÊàêÊ∞¥Âπ≥ÔºåÈÉ®ÂàÜÊô∫ËÉΩÂ∫¶‰∏çÂ§üÁöÑÂ§ßÊ®°ÂûãÂÆπÊòìÂá∫Èîô | Â§çÊùÇÊü•ËØ¢ÂíåËøûÁª≠ÂØπËØùÂú∫ÊôØ |

---

## üèÜ Ê£ÄÁ¥¢ÁªìÊûúÁ≤æÊéíÂ∫è

GloVe, BERTÂíåÂÖ∂ÂÆÉÊñáÊú¨ÂêëÈáèÂåñÊ®°ÂûãÈÄüÂ∫¶ËæÉÂø´Ôºå‰ΩÜÊñáÊú¨ÁöÑÁõ∏ÂÖ≥ÊÄßÂåπÈÖçËÆ°ÁÆóËÉΩÂäõÊúâÈôê„ÄÇÁõÆÂâç‰∏ªÊµÅÁöÑÊäÄÊúØÊû∂ÊûÑ‰∏∫È¶ñÂÖà‰ΩøÁî®GloVeÂíåÂÖ∂ÂÆÉÂêëÈáèË°®ÂæÅËøõË°åÂàùËΩÆÁ≠õÈÄâÔºåÁÑ∂ÂêéÂÜç‰ΩøÁî®Â§ßÂûãÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãËøõË°åÁªìÊûúÁ≤æÊéíÂ∫è„ÄÇÁ≥ªÁªüÁêÜËÆ∫‰∏äÊîØÊåÅÊâÄÊúâÁöÑÂü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑReRankÊ®°Âûã„ÄÇÂΩìÂâçÂ∑≤ÈÄöËøáÊµãËØïÁöÑ‰ª£Ë°®ÊÄßÊ®°ÂûãÂåÖÊã¨Ôºö

### **ms-marco-MiniLM-L6-v2**
- **Êû∂ÊûÑ**ÔºöÂü∫‰∫éCrossEncoderÊû∂ÊûÑÁöÑÊ∑±Â∫¶Â≠¶‰π†Ê®°Âûã
- **Ê®°ÂûãÂ§ßÂ∞è**Ôºö100M+
- **ÈÉ®ÁΩ≤ÊñπÂºè**ÔºöÁ≥ªÁªüÂèëÂ∏ÉÁöÑÁßëÁ†îÁâà‰∏≠ÈªòËÆ§‰ΩøÁî®ËØ•Ê®°Âûã
- **ËÆ°ÁÆóË¶ÅÊ±Ç**ÔºöÂü∫‰∫éCPUÁöÑËÆ°ÁÆóÂç≥ÂèØÊîØÊåÅÔºåËÆ°ÁÆóÂºÄÈîÄ‰∏çÂ§ß

### **bge-reranker-v2-m3**
- **ÁâπÁÇπ**ÔºöÂ§ßÂûãÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÔºåÁõ∏ÂÖ≥ÊÄßËÆ°ÁÆóÁªìÊûúÊûÅ‰Ω≥
- **Ê®°ÂûãÂ§ßÂ∞è**ÔºöAround 2G
- **ÈÉ®ÁΩ≤ÊñπÂºè**ÔºöÁî±‰∫éÊ®°Âûã‰ΩìÈáèËøáÂ§ßÔºåÈªòËÆ§ÊÉÖÂÜµ‰∏çÈöèÁ≥ªÁªüÂèëÂ∏ÉÔºåÈúÄÁî±ËΩØ‰ª∂ÂÆòÊñπ‰∫∫Â∑•ÂÆâË£ÖÂπ∂ÈÖçÁΩÆGPUÂäüËÉΩÊîØÊåÅ

### Â∫îÁî®Êâ©Â±ï
‰ª•‰∏äÊ£ÄÁ¥¢ÁªìÊûúÁ≤æÊéíÂ∫èÊ®°ÂûãËøòÂ∫îÁî®Âú®WEBÊêúÁ¥¢ÔºàAgentÂ∑•ÂÖ∑ÔºâÁªìÊûúÈáçÊéíÂ∫èÂäüËÉΩ‰∏≠ÔºåÊèê‰æõÊõ¥Á≤æÂáÜÁöÑÊêúÁ¥¢ÁªìÊûú„ÄÇ

---

---

# üìö Text Vector Database and Key Configuration Guide

> **Text Vector Database** is an intelligent text processing system that automatically scans text files in specified directories, intelligently segments text into chunks, and converts "text chunks" into fixed-length numerical vectors. The system employs multiple advanced methods for text chunk retrieval and recall, and uses high-precision deep learning models for fine-ranking of recalled results. Main application scenarios include fuzzy content retrieval of massive text files and retrieval-augmented generation (RAG) for large language models.

---

## üìÅ Supported File Types

The system currently supports the vast majority of common text file types in the market, including PDF, Word, Excel, PPT, TXT, Markdown, etc. For different file characteristics, the system performs targeted special processing:

| File Type | Extension | Processing Method Description |
|:---------:|:---------:|:-----------------------------|
| **TXT** | `.txt` | If there is one blank line between paragraphs (i.e., two `\n\n`), the system will default this format as the user-specified text chunk cutting method and avoid cutting large paragraphs, merging small paragraphs backward. |
| **PDF** | `.pdf` | The system attempts to repair paragraphs from incorrectly segmented text read from PDFs. If tables exist in the document, only tables with complete borders can be identified, and the entire table will be converted to Markdown format and treated as a complete text chunk without cutting. |
| **MS Word** | `.doc/.docx` | Text chunk cutting method is the same as TXT. If tables exist in the document, the entire table will be converted to Markdown format and treated as a complete text chunk without cutting. |
| **MS Excel** | `.xls/.xlsx` | The entire table in a worksheet will be converted to Markdown format and treated as a complete text chunk without cutting. If the table is very large, it's recommended to convert to CSV format first, and the system will perform special processing. |
| **CSV** | `.csv` | Must have headers by default. Each row of data will be processed as multiple key-value corresponding JSON data, where field names in the header are keys and data units in rows are values. Each row is a text chunk without cutting. |
| **Markdown** | `.md` | Preferred format for large models. Special processing is done for titles and their leading paragraphs. Text blocks formed by title + paragraph are not further cut or merged. Special annotations are made for tables, quotes, lists, code blocks, etc. |
| **HTML** | `.html/.htm` | Convert HTML to Markdown format, then process it. Processing method is the same as Markdown. |
| **MS PPT** | `.ppt/.pptx` | Text chunk cutting method is the same as TXT. If tables exist in PPT, the entire table will be converted to Markdown format and treated as a complete text chunk without cutting. |

---

## üî™ Text Chunk Processing Mechanism

The text database intelligently cuts longer text content into multiple small text segments, which is necessary under current technical conditions:

### Why Text Chunking is Needed?

- **üîç Semantic Information Preservation**: When vectorizing text, overly long text tends to blur semantic information. When searching text chunks using user input questions, the relevance calculation effect between long text and user questions based on vector similarity comparison will be greatly reduced.

- **üìè Model Input Limitations**: Text vectorization models usually have input length restrictions. For example, models like BERT and BGE typically limit input tokens to 512, and overly long text is often directly truncated and discarded.

- **ü§ñ Large Model Compatibility**: Large language models usually have input length restrictions. In applications like retrieval-augmented generation, if the retrieved text length exceeds the input length limit of large models, it will be directly truncated and discarded.

### Text Chunk Length Configuration Recommendations

Given that most text vectorization models have input length restrictions of 512 tokens, when setting up the text database, the maximum text chunk length limit should consider this factor:

| Language | Maximum Text Chunk Length Setting | Description |
|:--------:|:--------------------------------:|:------------|
| **Chinese** | 512 tokens correspond to 512 Chinese word groups | For safety, character length should not exceed **1000**, default value is **800** |
| **English** | 512 tokens correspond to 512 words | For safety, character length should not exceed **2000**, default value is **800** |

As for the **minimum text chunk length** limit, it can be set according to specific scenarios, with a default value of **500**. When the paragraph identified by the system is smaller than the minimum text chunk length, it will merge paragraphs backward by default until the length meets the minimum length requirement.

---

## üß† Text Vectorization Methods

This system supports multiple advanced text vectorization technologies:

### **GloVe** - Shallow Semantic Vectorization
- **Characteristics**: GloVe neural network models are usually small, with input word sequence correlation window length typically being 5
- **Advantages**: Fast training speed, low resource consumption
- **Limitations**: Difficulty in capturing long-distance correlation relationships between text vocabulary, semantic relevance is "shallow semantics"
- **Application**: The system has built-in GloVe models pre-trained on large text materials such as "People's Daily"
- **Extension**: Provides self-training functionality for GloVe models, which can train custom models that highly reflect user domain data characteristics after "domain vocabulary recognition"

### **DistillBERT** - Deep Semantic Vectorization
- **Characteristics**: Distilled pre-trained version of BERT model for text data vectorization
- **Advantages**: Attention mechanism is good at capturing long-distance dependency relationships between vocabulary, semantic relevance is "deep semantics"
- **Technology**: It is a serialized model itself, word sequences can directly generate sentence vectors without involving weighted average conversion from word vectors to sentence vectors like GloVe
- **Efficiency**: Performance is no different from BERT, but volume is 70% smaller (250M), suitable for server-side deployment

### Performance Ranking
According to system practical experience, the retrieval effect ranking of various vectorization methods is:
**Self-trained GloVe > DistillBERT > Pre-trained GloVe**

---

## üîç Vector Indexing Methods

This system mainly supports three major vector indexing technology systems:

| Index Method Name | Index Type | Advantages | Disadvantages | Applicable Scenarios |
|:-----------------:|:----------:|:-----------|:---------------|:---------------------|
| **HNSW** | Network Graph | Extremely fast retrieval speed | Very slow index building speed | Face recognition and other image ultra-fast retrieval |
| **E2LSH** | Hash Algorithm | Both retrieval speed and index building speed are acceptable | General recall accuracy | Medium-scale data retrieval |
| **Flat Index** | Parallel Linear Search | 100% recall accuracy | General retrieval speed | Small-scale text database scenarios |

In practice, the indexing method should be determined according to scenario requirements. For example, in small-scale text database scenarios, using flat indexing is sufficient; while in scenarios requiring ultra-fast retrieval, using HNSW is better.

---

## üîé Retrieval Methods

This system supports multiple retrieval strategies, including both traditional BM25 retrieval methods based on keyword matching and semantic relevance retrieval methods based on vector similarity adopted in the AI era. It can also perform multi-channel recall comprehensive ranking of retrieval results from both methods:

| Retrieval Method Name | Description | Advantages | Disadvantages | Applicable Scenarios |
|:---------------------:|:------------|:-----------|:---------------|:---------------------|
| **BM25** | Based on keyword matching and TF-IDF scoring calculation of keywords for ranking and recall | Not limited by text length, fast retrieval speed | Cannot calculate semantic similarity, must exactly match words | Precise keyword search |
| **Vector Similarity** | Based on Euclidean distance between vectors for similarity ranking and recall | Can calculate semantic similarity, suitable for fuzzy text search | Limited by text length, semantic information of long text vectors is blurred | Semantic similarity search |
| **Comprehensive Retrieval** | Comprehensive ranking of multi-channel recall results combining BM25 and vector similarity retrieval results | Absorbs advantages of both retrieval methods while avoiding their disadvantages | High computational cost, slow in massive data | High-precision comprehensive search |

---

## üéØ User Retrieval Question Parsing Methods

In information retrieval, due to users' colloquial expressions and other issues, "user intent understanding difficulties" often occur, meaning the system cannot use optimal retrieval statements to query the information users want to obtain. To solve this problem, this system has added optional configuration for large model parsing of retrieval questions:

| Parsing Method | Description | Advantages | Disadvantages | Applicable Scenarios |
|:--------------:|:------------|:-----------|:---------------|:---------------------|
| **User Original Question** | Use user input questions for direct retrieval | Simple, not prone to errors, fast response speed | User questions are usually colloquial, questions input in continuous conversations lack context information and cannot be retrieved | Simple query scenarios |
| **Large Model Parsing Retrieval Questions** | Large models regenerate appropriate retrieval questions based on user input questions | Can generate more retrieval-suitable complete statements, still generate complete retrieval questions based on context in continuous conversations | Depends on large models' user intent understanding and generation level, some models with insufficient intelligence are prone to errors | Complex queries and continuous conversation scenarios |

---

## üèÜ Retrieval Result Fine-Ranking

GloVe, BERT and other text vectorization models are fast, but their text relevance matching calculation capabilities are limited. The current mainstream technical architecture is to first use GloVe and other vector representations for initial screening, then use large deep learning models for result fine-ranking. The system theoretically supports all deep learning-based ReRank models. Currently tested representative models include:

### **ms-marco-MiniLM-L6-v2**
- **Architecture**: Deep learning model based on CrossEncoder architecture
- **Model Size**: 100M+
- **Deployment Method**: Default model used in the research version released by the system
- **Computing Requirements**: Can be supported by CPU-based computing with low computational overhead

### **bge-reranker-v2-m3**
- **Characteristics**: Large deep learning model with excellent relevance calculation results
- **Model Size**: Around 2G
- **Deployment Method**: Due to large model volume, not included in system release by default, requires manual installation by software officials and GPU function support configuration

### Application Extension
The above retrieval result fine-ranking models are also applied in WEB search (Agent tool) result re-ranking functionality, providing more accurate search results.
