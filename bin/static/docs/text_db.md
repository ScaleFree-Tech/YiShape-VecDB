

[返回](/mag/doc_detail/main)

---

## 文本库及关键配置说明

文本向量库是一种能够自动扫描指定目录中的文本文件、对文本进行分块，并将“文本块”转换为固定长度数值向量的数据库。其使用多种方法对“文本块”进行检索召回，并使用精度更高的深度学习等模型对召回的结果进行精排序。文本向量库的使用场景包括海量文本文件的内容模糊检索、面向大语言模型的检索增强生成等。

### <a name="supported_files"></a>支持的文件类型

系统当前支持世面上绝大多数常见的文本文件类型，如PDF、Word、Excel、PPT、TXT、MarkDown等，针对文件特点，系统还会进行针对性特殊处理，具体如下：

| 类型 | 扩展名 | 处理方法说明 |
| :---:| :---: | :--- |
| TXT | .txt | 如果段落间有一个空行（即两个\n\n），系统将默认该格式为用户指定的文本块切割方法，并尽量避免再对大的段落切割，小的段落向后合并。 |
| PDF | .pdf |会尝试对PDF中读出的未正确分段的文本进行段落修复。如果文档中有表格存在，只有具有完整边框的表格能被识别，整个表格将被转换为MarkDown格式并视为一整个文本块，不进行切割。 |
| MS Word | .doc/.docx | 文本块切割方法同TXT。如果文档中有表格存在，整个表格将被转换为MarkDown格式并视为一整个文本块，不进行切割。 |
| MS Excel | .xls/.xlsx | 整个标签页中的表格将被转换为MarkDown格式并视为一整个文本块，不进行切割。如果表格很大，建议先转为CSV格式，系统将做特殊处理。 |
| CSV | .csv | 默认必须有表头存在，数据的每一行都将被处理为多个键-值对应的JSON数据，其中表头中的字段名为键、行中的数据单元为值，每行为一个文本块，不进行切割。 |
| MarkDown | .md | 大模型首选格式。针对标题及引领的段落做了特别处理，标题+段落形成的文本块不做进一步切割与合并。针对表格、引用、列表、代码块等内容做了特别标注。 |
| HTML | .html/.htm | 将HTML转换为MarkDown格式，然后进行处理，处理方式同MarkDown。 |
| MS PPT | .ppt/.pptx | 文本块切割方法同TXT。如果PPT中有表格存在，整个表格将被转换为MarkDown格式并视为一整个文本块，不进行切割。|

### 文本块

文本库会将文本文件较长的内容切割为多个小段文本，这在当前的技术条件下是必要的。

- **将文本向量化时，过长的文本容易模糊语义信息**。在使用用户输入的问题搜索文本块时，基于向量相似性比对的长文本与用户问题相关性计算效果将大打折扣。

- **文本向量化模型通常有输入长度限制**。如BERT、BGE等模型的输入Token数通常限制512，过长的文本往往会被直接截断丢弃。

- **大语言模型通常有输入长度限制**。在检索增强生成等应用中，如果检索出的文本长度超出大模型的输出长度限制，将被直接截断丢弃。

鉴于大多数文本向量化模型的输入长度限制为512Token，在文本库设置时文本块的最大长度限制时应考虑该因素，具体如下：

| 语言 | 最大文本块长度设置 |
| :---: | :------- |
| 中文 | 512Token对应512个中文词组，保险起见字长度设置不超过 1000，默认值为800。 |
| 英文 | 512Token对应512个单词，保险起见字长度设置不超过 2000，默认值为800。 |

至于**最小文本块长度**限制，可根据具体场景设置，默认值500。当系统识别出的段落小于最小文本块长度时，默认会向后合并段落，直至长度符合最小长度要求。


### <a name="embedding_method"></a>文本向量化方法

本系统支持多种方法对文本进行向量化。

- **GloVe**. GloVe神经网络的模型通常较小，输入的词序列间的关联窗口长度通常为5，这难以捕捉文本词汇间长距离的关联关系，因此语义相关性只能称为“浅层语义”。本系统内置了在“人民日报”等大型文本材料上预训练的GloVe模型，但同时还提供了GloVe模型的自训练功能，可以在进行“领域词汇识别”后，自训练能高度体现用户领域数据特点的自定义GloVe模型，这种自训练模型在领域文本材料上检索效果通常较好。

- **DistillBert**. 本系统内置了BERT模型的蒸馏预训练版本：DistillBert，用于文本数据向量化。BERT模型中的注意力机制善于捕捉词汇间的长距离依赖关系，因此语义相关性为“深层语义”。BERT模型的另一个优点是本身为序列化模型，词序列可以直接生成句向量，不涉及类似GloVe的词向量-句向量的加权平均转换。原始BERT模型过大，不适合随服务端侧部署，系统内使用的DistillBert与BERT性能无异，但体量小70%（250M）。

以本系统的实操经验来看，各种向量化方法的检索效果排序为：自训练Glove > DistillBert > 预训练GloVe。

### <a name="vector_indexing"></a>向量索引方法

本系统主要支持三大向量索引技术体系。

| 索引方法名称 | 索引类型 | 优点 | 缺点 |
| :---------: | :-----: | :--- | :--- |
| HNSW | 网络图 | 检索速度极快 | 构建索引速度极慢 |
| E2LSH | 哈希算法 | 检索速度与索引构建速度均尚可 | 召回精度一般 |
| 扁平索引 | 并行线性搜索 | 召回精度100% | 检索速度一般 |

在实践中，需根据场景需求确定索引方法，如在小规模文本库场景中，使用扁平索引即可，而在人脸识别等图像极速检索等场景中，使用HNSW较好。


### <a name="search_method"></a>检索方法

本系统既支持在搜索引擎中广泛使用的基于关键词匹配的BM25检索方法，也支持人工智能时代所采用的基于向量相似度的语义相关性检索方法，并且可以将两种方法的检索结果进行多路召回综合排序。具体如下：

| 检索方法名称 | 说明 | 优点 | 缺点 |
| :---------: | :--- | :-- | :--|
| BM25 | 基于关键词匹配和关键词的TF-IDF等分值计算得分并排序召回 | 不受文本长度限制 | 无法计算语义相似性，必须精确匹配词 |
| 向量相似性 | 基于向量间的欧式距离进行相似性排序召回 | 能够计算语义相似性，适合文本模糊搜索 | 受文本长度限制，长文本向量的语义信息模糊 |
| 综合检索 | 综合BM25和向量相似性的检索结果进行多路召回结果综合排序 | 同时吸纳两种检索方法的优点，避免两种方法缺点 | 计算量大，在海量数据中速度慢 |

###  <a name="question_parse"></a>用户检索问题的解析方法(用户意图理解)

在信息检索中，由于用户的口语话表达等问题，经常出现“用户意图理解困难”问题，即系统不能使用最优的检索语句去查询用户想要获得的信息。本系统为了解决以上问题，加入了大模型解析检索问题的可选配置，具体如下：

| 解析方法 | 说明 | 优点 | 缺点 |
| :------: | :--- | :--- | :--- |
| 用户原始问题 | 使用用户输入的问题直接检索 | 简单、不易出错 | 用户问题通常口语话，在连续对话中输入的问题无上下文信息，无法检索 |
| 大模型解析检索问题 | 根据用户输入的问题由大模型重新生成合适的检索问题 | 能够生成更加适合检索的完成语句，在连续对话中仍能根据上下文生成完整的检索问题 | 依赖于大模型的用户意图理解和生成水平，部分智能度不够的大模型容易出错 |

### <a name="rerank"></a>检索结果精排

GloVe、BERT等文本向量化模型速度较快，但文本的相关性匹配计算能力有限，目前主流的技术架构为首先使用GloVe等向量表征进行初轮筛选，然后再使用大型深度学习模型进行结果精排。系统理论上支持所有的基于深度学习的ReRank模型，但由于实验时间有限，当前已通过测试的两种代表性模型为：

- **ms-marco-MiniLM-L6-v2**. 这是一种基于CrossEncoder架构的深度学习模型，模型大小为100M+。本系统发布的科研版中默认使用该模型，基于CPU的计算即可支持，计算开销不大。

- **bge-reranker-v2-m3**. 这是一种大型的深度学习模型，相关性计算结果极佳，模型大小为2G左右。由于模型的体量过大，默认情况不随系统发布，需由本软件官方人工安装并配置GPU功能支持。

另外，以上检索结果精排模型还应用在WEB搜索（Agent工具）结果重排功能中。
